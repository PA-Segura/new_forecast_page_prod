"""
Servicio web FastAPI para consultar predicciones de calidad del aire.
Proporciona endpoints REST para acceder a datos de la base de datos PostgreSQL.

Autor: Sistema de Pron√≥stico de Calidad del Aire
Versi√≥n: 1.0
"""

import os
import logging
import netrc
from datetime import datetime, timedelta
from typing import Optional, List, Dict, Any
from contextlib import asynccontextmanager

import uvicorn
from fastapi import FastAPI, HTTPException, Query, Path
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field
import asyncpg
from asyncpg import Pool

# Configuraci√≥n de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Modelos Pydantic para validaci√≥n de datos
class PronosticoItem(BaseModel):
    """Modelo para un elemento de pron√≥stico individual"""
    dia: str = Field(..., description="Fecha del pron√≥stico en formato YYYY-MM-DD")
    valor: float = Field(..., description="Valor de la predicci√≥n")
    fuente: str = Field(..., description="Fuente de la predicci√≥n")
    id_est: str = Field(..., description="ID de la estaci√≥n con valor m√°ximo")
    hora: str = Field(..., description="Hora del pron√≥stico (HH:MM)")

class PronosticoResponse(BaseModel):
    """Modelo para la respuesta del endpoint de pron√≥sticos"""
    ciudad: str = Field(..., description="Ciudad de la predicci√≥n")
    fecha_pron: str = Field(..., description="Fecha de pron√≥stico en formato YYYY-MM-DD")
    modelo_id: str = Field(..., description="ID del modelo utilizado")
    unidades: str = Field(..., description="Unidades de medida")
    pronos: List[PronosticoItem] = Field(..., description="Lista de pron√≥sticos")

class ErrorResponse(BaseModel):
    """Modelo para respuestas de error"""
    message: str = Field(..., description="Mensaje de error")

# Funci√≥n para obtener credenciales AMATE-SOLOREAD (igual que postgres_data_service.py)
def get_db_config():
    """Obtiene configuraci√≥n de base de datos usando credenciales AMATE-SOLOREAD"""
    try:
        # Obtener credenciales desde .netrc (igual que el sistema principal)
        secrets = netrc.netrc()
        login, account, password = secrets.hosts['AMATE-SOLOREAD']
        
        # Configuraci√≥n de conexi√≥n (igual que postgres_data_service.py)
        host = account or os.getenv('DB_HOST', '132.248.8.152')
        database = os.getenv('DB_NAME', 'contingencia')
        
        return {
            'host': host,
            'port': int(os.getenv('DB_PORT', '5432')),
            'user': login,
            'password': password,
            'database': database
        }
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è No se pudieron obtener credenciales AMATE-SOLOREAD: {e}")
        # Fallback a variables de entorno
        return {
            'host': os.getenv('DB_HOST', '132.248.8.152'),
            'port': int(os.getenv('DB_PORT', '5432')),
            'user': os.getenv('DB_USER', 'postgres'),
            'password': os.getenv('DB_PASSWORD', ''),
            'database': os.getenv('DB_NAME', 'contingencia')
        }

# Configuraci√≥n de base de datos usando credenciales AMATE-SOLOREAD
DB_CONFIG = get_db_config()

# Configuraci√≥n del servidor API
API_CONFIG = {
    'host': os.getenv('API_HOST', '0.0.0.0'),
    'port': int(os.getenv('API_PORT', '8888')),
    'debug': os.getenv('API_DEBUG', 'false').lower() == 'true'
}

# Pool de conexiones global
db_pool: Optional[Pool] = None

class ForecastProcessor:
    """Procesa datos de pron√≥sticos desde la base de datos y genera respuestas JSON"""
    
    def __init__(self, contaminante: str, ciudad: str, fecha_datetime: datetime):
        """
        Inicializa el procesador de pron√≥sticos.
        
        Args:
            contaminante: Tipo de contaminante (ozono, pm10, etc.)
            ciudad: Ciudad o estaci√≥n (CDMX, UIZ, etc.)
            fecha_datetime: Fecha base del pron√≥stico
        """
        self.contaminante = contaminante.lower()
        self.ciudad = ciudad.upper()
        self.fecha_base = fecha_datetime
        
    def get_table_name(self) -> str:
        """Mapea el contaminante a su tabla correspondiente"""
        table_mapping = {
            'ozono': 'forecast_otres',
            'co': 'forecast_co',
            'no': 'forecast_no',
            'nodos': 'forecast_nodos',
            'nox': 'forecast_nox',
            'pmco': 'forecast_pmco',
            'pm10': 'forecast_pmdiez',
            'pm25': 'forecast_pmdoscinco',
            'sodos': 'forecast_sodos'
        }
        return table_mapping.get(self.contaminante, 'forecast_otres')
    
    def get_unidades(self) -> str:
        """Obtiene las unidades seg√∫n el contaminante"""
        unidades_map = {
            'ozono': 'ppb',
            'co': 'ppm',
            'no': 'ppb',
            'nodos': 'ppb',
            'nox': 'ppb',
            'pmco': 'Œºg/m¬≥',
            'pm10': 'Œºg/m¬≥',
            'pm25': 'Œºg/m¬≥',
            'sodos': 'ppb'
        }
        return unidades_map.get(self.contaminante, 'ppb')
    
    async def fetch_raw_data(self, pool: Pool) -> list:
        """
        Ejecuta la consulta SQL y obtiene los datos crudos de la base de datos.
        
        Args:
            pool: Pool de conexiones de asyncpg
            
        Returns:
            Lista de registros de la base de datos
        """
        table_name = self.get_table_name()
        
        # Construir query seg√∫n tabla y ciudad
        if table_name == 'forecast_otres':
            if self.ciudad == 'CDMX':
                # Para CDMX: obtener todas las estaciones
                query = """
                SELECT 
                    fecha,
                    id_est as estacion,
                    hour_p01, hour_p02, hour_p03, hour_p04, hour_p05, hour_p06,
                    hour_p07, hour_p08, hour_p09, hour_p10, hour_p11, hour_p12,
                    hour_p13, hour_p14, hour_p15, hour_p16, hour_p17, hour_p18,
                    hour_p19, hour_p20, hour_p21, hour_p22, hour_p23, hour_p24
                FROM forecast_otres 
                WHERE DATE(fecha) = $1 
                AND id_tipo_pronostico = 7
                ORDER BY fecha ASC
                """
                params = [self.fecha_base]
            else:
                # Para estaci√≥n espec√≠fica
                query = """
                SELECT 
                    fecha,
                    id_est as estacion,
                    hour_p01, hour_p02, hour_p03, hour_p04, hour_p05, hour_p06,
                    hour_p07, hour_p08, hour_p09, hour_p10, hour_p11, hour_p12,
                    hour_p13, hour_p14, hour_p15, hour_p16, hour_p17, hour_p18,
                    hour_p19, hour_p20, hour_p21, hour_p22, hour_p23, hour_p24
                FROM forecast_otres 
                WHERE DATE(fecha) = $1 
                AND id_tipo_pronostico = 7
                AND id_est = $2
                ORDER BY fecha ASC
                """
                params = [self.fecha_base, self.ciudad]
        else:
            # Tablas de estad√≠sticas (co, pm10, etc.)
            query = """
            SELECT 
                fecha,
                avg_hour_p01, avg_hour_p02, avg_hour_p03, avg_hour_p04, avg_hour_p05, avg_hour_p06,
                avg_hour_p07, avg_hour_p08, avg_hour_p09, avg_hour_p10, avg_hour_p11, avg_hour_p12,
                avg_hour_p13, avg_hour_p14, avg_hour_p15, avg_hour_p16, avg_hour_p17, avg_hour_p18,
                avg_hour_p19, avg_hour_p20, avg_hour_p21, avg_hour_p22, avg_hour_p23, avg_hour_p24
            FROM {} 
            WHERE DATE(fecha) = $1
            ORDER BY fecha ASC
            """.format(table_name)
            params = [self.fecha_base]
        
        # Ejecutar consulta
        async with pool.acquire() as conn:
            rows = await conn.fetch(query, *params)
        
        return rows
    
    def process_hourly_forecasts(self, rows: list) -> Dict[str, Dict[str, Any]]:
        """
        Procesa los pron√≥sticos horarios y calcula el m√°ximo por d√≠a.
        
        Args:
            rows: Registros de la base de datos
            
        Returns:
            Diccionario con {fecha_str: {'valor': max, 'id_est': estacion, 'hora': hora}}
        """
        if not rows:
            return {}
        
        # Diccionario para almacenar todos los valores por d√≠a con metadata
        valores_por_dia = {}
        
        # Determinar si es tabla de ozono (hour_pXX) o estad√≠sticas (avg_hour_pXX)
        first_row = rows[0]
        is_ozono_table = 'hour_p01' in first_row
        prefix = 'hour_p' if is_ozono_table else 'avg_hour_p'
        
        # Procesar cada fila (cada fila es una estaci√≥n o registro)
        for row in rows:
            fecha_base_row = row['fecha']
            estacion = row.get('estacion', 'CDMX')  # Obtener estaci√≥n o usar CDMX por defecto
            
            # Procesar cada hora (p01 a p24)
            for hour_num in range(1, 25):
                hour_col = f'{prefix}{hour_num:02d}'
                
                if hour_col in row and row[hour_col] is not None:
                    valor = float(row[hour_col])
                    
                    # Calcular la fecha y hora real del pron√≥stico
                    # hour_p01 = fecha_base + 1 hora, hour_p02 = fecha_base + 2 horas, etc.
                    if isinstance(fecha_base_row, datetime):
                        fecha_hora_pronostico = fecha_base_row + timedelta(hours=hour_num)
                    else:
                        fecha_base_dt = datetime.strptime(str(fecha_base_row), '%Y-%m-%d %H:%M:%S')
                        fecha_hora_pronostico = fecha_base_dt + timedelta(hours=hour_num)
                    
                    # Extraer d√≠a y hora
                    dia_str = fecha_hora_pronostico.strftime('%Y-%m-%d')
                    hora_str = fecha_hora_pronostico.strftime('%H:%M')
                    
                    # Guardar el valor con metadata para este d√≠a
                    if dia_str not in valores_por_dia:
                        valores_por_dia[dia_str] = []
                    
                    valores_por_dia[dia_str].append({
                        'valor': valor,
                        'id_est': estacion,
                        'hora': hora_str
                    })
        
        # Calcular el m√°ximo por cada d√≠a y guardar la metadata del m√°ximo
        max_por_dia = {}
        for dia, registros in valores_por_dia.items():
            # Encontrar el registro con el valor m√°ximo
            registro_max = max(registros, key=lambda x: x['valor'])
            max_por_dia[dia] = registro_max
        
        # Ordenar por fecha
        max_por_dia_ordenado = dict(sorted(max_por_dia.items()))
        
        return max_por_dia_ordenado
    
    def build_response(self, daily_max: Dict[str, Dict[str, Any]]) -> PronosticoResponse:
        """
        Construye la respuesta JSON final.
        
        Args:
            daily_max: Diccionario con valores m√°ximos por d√≠a y metadata
            
        Returns:
            PronosticoResponse con el formato requerido
        """
        # Construir lista de pron√≥sticos con toda la metadata
        pronosticos = [
            PronosticoItem(
                dia=dia_str,
                valor=round(registro['valor'], 2),  # Redondear a 2 decimales
                fuente="pronostico",  # Default por ahora
                id_est=registro['id_est'],
                hora=registro['hora']
            )
            for dia_str, registro in daily_max.items()
        ]
        
        # Construir respuesta
        response = PronosticoResponse(
            ciudad=self.ciudad,
            fecha_pron=self.fecha_base.strftime('%Y-%m-%d'),
            modelo_id="7",  # id_tipo_pronostico
            unidades=self.get_unidades(),
            pronos=pronosticos
        )
        
        return response

async def generate_forecast_json(contaminante: str, ciudad: str, fecha_datetime: datetime) -> PronosticoResponse:
    """
    Genera la respuesta JSON completa para pron√≥sticos de contaminantes.
    
    Args:
        contaminante: Tipo de contaminante (ej: ozono, pm10, co, etc.)
        ciudad: Ciudad de la predicci√≥n (ej: CDMX, UIZ, etc.)
        fecha_datetime: Fecha de pron√≥stico como objeto datetime
    
    Returns:
        PronosticoResponse: Respuesta JSON formateada
    """
    # Crear procesador de pron√≥sticos
    processor = ForecastProcessor(contaminante, ciudad, fecha_datetime)
    
    # Obtener datos crudos de la base de datos
    rows = await processor.fetch_raw_data(db_pool)
    
    if not rows:
        raise HTTPException(
            status_code=404,
            detail="No se encontraron datos"
        )
    
    # Procesar pron√≥sticos horarios y calcular m√°ximos por d√≠a
    daily_max = processor.process_hourly_forecasts(rows)
    
    # Construir respuesta JSON
    response = processor.build_response(daily_max)
    
    return response

@asynccontextmanager
async def lifespan(app: FastAPI):
    """Gesti√≥n del ciclo de vida de la aplicaci√≥n"""
    global db_pool
    
    # Inicializaci√≥n
    logger.info("üöÄ Iniciando servicio de pron√≥sticos de calidad del aire")
    
    try:
        # Crear pool de conexiones
        db_pool = await asyncpg.create_pool(
            host=DB_CONFIG['host'],
            port=DB_CONFIG['port'],
            user=DB_CONFIG['user'],
            password=DB_CONFIG['password'],
            database=DB_CONFIG['database'],
            min_size=1,
            max_size=10
        )
        logger.info("‚úÖ Pool de conexiones PostgreSQL creado exitosamente")
        
        # Verificar conexi√≥n
        async with db_pool.acquire() as conn:
            await conn.fetchval('SELECT 1')
        logger.info("‚úÖ Conexi√≥n a base de datos verificada")
        
    except Exception as e:
        logger.error(f"‚ùå Error al conectar con la base de datos: {e}")
        raise
    
    yield
    
    # Limpieza
    if db_pool:
        await db_pool.close()
        logger.info("üîå Pool de conexiones cerrado")

# Crear aplicaci√≥n FastAPI
app = FastAPI(
    title="Servicio de Pron√≥sticos de Calidad del Aire",
    description="API REST para consultar predicciones de calidad del aire desde PostgreSQL",
    version="1.0.0",
    lifespan=lifespan
)

async def get_db_connection():
    """Obtener conexi√≥n de la base de datos"""
    if not db_pool:
        raise HTTPException(status_code=500, detail="Pool de base de datos no disponible")
    return db_pool.acquire()

@app.get("/", response_model=Dict[str, Any])
async def root():
    """Endpoint ra√≠z con informaci√≥n del servicio"""
    return {
        "service": "Pron√≥sticos de Calidad del Aire API",
        "version": "1.0.0",
        "status": "active",
        "database": "PostgreSQL (AMATE-SOLOREAD)",
        "endpoints": {
            "ai_vi_transformer01": "/ai_vi_transformer01/{contaminante}/{ciudad}/{fecha_pron}",
            "pronosticos_ia": "/get_ia_resume/{ciudad}/{fecha_pron}",
            "health": "/health",
            "docs": "/docs"
        },
        "contaminantes_disponibles": {
            "ozono": "Ozono (ai_vi_transformer01) - forecast_otres",
            "co": "Mon√≥xido de Carbono (ai_vi_transformer01) - forecast_co",
            "no": "√ìxido N√≠trico (ai_vi_transformer01) - forecast_no",
            "nodos": "Di√≥xido de Nitr√≥geno (ai_vi_transformer01) - forecast_nodos",
            "nox": "√ìxidos de Nitr√≥geno (ai_vi_transformer01) - forecast_nox",
            "pmco": "PMco (ai_vi_transformer01) - forecast_pmco",
            "pm10": "PM10 (ai_vi_transformer01) - forecast_pmdiez",
            "pm25": "PM2.5 (ai_vi_transformer01) - forecast_pmdoscinco",
            "sodos": "Di√≥xido de Azufre (ai_vi_transformer01) - forecast_sodos"
        },
        "ciudades_disponibles": {
            "CDMX": "Ciudad de M√©xico (m√°ximo de todas las estaciones)",
            "UIZ": "Estaci√≥n UIZ", "AJU": "Estaci√≥n AJU", "ATI": "Estaci√≥n ATI", 
            "CUA": "Estaci√≥n CUA", "SFE": "Estaci√≥n SFE", "SAG": "Estaci√≥n SAG", 
            "CUT": "Estaci√≥n CUT", "PED": "Estaci√≥n PED", "TAH": "Estaci√≥n TAH", 
            "GAM": "Estaci√≥n GAM", "IZT": "Estaci√≥n IZT", "CCA": "Estaci√≥n CCA", 
            "HGM": "Estaci√≥n HGM", "LPR": "Estaci√≥n LPR", "MGH": "Estaci√≥n MGH", 
            "CAM": "Estaci√≥n CAM", "FAC": "Estaci√≥n FAC", "TLA": "Estaci√≥n TLA", 
            "MER": "Estaci√≥n MER", "XAL": "Estaci√≥n XAL", "LLA": "Estaci√≥n LLA", 
            "TLI": "Estaci√≥n TLI", "UAX": "Estaci√≥n UAX", "BJU": "Estaci√≥n BJU", 
            "MPA": "Estaci√≥n MPA", "MON": "Estaci√≥n MON", "NEZ": "Estaci√≥n NEZ", 
            "INN": "Estaci√≥n INN", "AJM": "Estaci√≥n AJM", "VIF": "Estaci√≥n VIF"
        }
    }

@app.get("/health", response_model=Dict[str, str])
async def health_check():
    """Endpoint de verificaci√≥n de salud del servicio"""
    try:
        async with db_pool.acquire() as conn:
            await conn.fetchval('SELECT 1')
        return {"status": "healthy", "database": "connected"}
    except Exception as e:
        logger.error(f"Health check failed: {e}")
        raise HTTPException(status_code=503, detail="Servicio no disponible")

@app.get(
    "/ai_vi_transformer01/{contaminante}/{ciudad}/{fecha_pron}",
    response_model=PronosticoResponse,
    responses={
        404: {"model": ErrorResponse, "description": "No se encontraron datos"},
        500: {"model": ErrorResponse, "description": "Error interno del servidor"}
    }
)
async def get_ai_vi_transformer01(
    contaminante: str = Path(..., description="Contaminante (ej: ozono, pm10, co, etc.)"),
    ciudad: str = Path(..., description="Ciudad de la predicci√≥n"),
    fecha_pron: str = Path(..., description="Fecha de pron√≥stico en formato YYYY-MM-DD")
):
    """
    Obtiene resumen de pron√≥sticos del modelo AI VI Transformer01 para una ciudad y fecha espec√≠fica.
    
    Args:
        contaminante: Tipo de contaminante (ej: ozono, pm10, co, etc.)
        ciudad: Ciudad de la predicci√≥n
        fecha_pron: Fecha de pron√≥stico en formato YYYY-MM-DD
    
    Returns:
        PronosticoResponse: Datos de pron√≥stico agrupados por ciudad y fecha
    """
    try:
        # Validar formato de fecha
        try:
            datetime.strptime(fecha_pron, '%Y-%m-%d')
        except ValueError:
            raise HTTPException(
                status_code=400, 
                detail="Formato de fecha inv√°lido. Use YYYY-MM-DD"
            )
        
        # Convertir fecha string a datetime para PostgreSQL
        fecha_datetime = datetime.strptime(fecha_pron, '%Y-%m-%d')
        
        # Usar la funci√≥n centralizada para generar el JSON
        response = await generate_forecast_json(contaminante, ciudad, fecha_datetime)
        
        logger.info(f"‚úÖ Consulta exitosa: {ciudad}, {fecha_pron}, {len(response.pronos)} registros")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en consulta: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno del servidor: {str(e)}"
        )

@app.get(
    "/get_ia_resume/{ciudad}/{fecha_pron}",
    response_model=PronosticoResponse,
    responses={
        404: {"model": ErrorResponse, "description": "No se encontraron datos"},
        500: {"model": ErrorResponse, "description": "Error interno del servidor"}
    }
)
async def get_ia_resume(
    ciudad: str = Path(..., description="Ciudad de la predicci√≥n"),
    fecha_pron: str = Path(..., description="Fecha de pron√≥stico en formato YYYY-MM-DD")
):
    """
    Obtiene resumen de pron√≥sticos de IA para una ciudad y fecha espec√≠fica.
    Endpoint alternativo que agrupa por ciudad y fecha sin especificar componente.
    """
    try:
        # Validar formato de fecha
        try:
            datetime.strptime(fecha_pron, '%Y-%m-%d')
        except ValueError:
            raise HTTPException(
                status_code=400, 
                detail="Formato de fecha inv√°lido. Use YYYY-MM-DD"
            )
        
        # Construir consulta SQL agrupada
        query = """
        SELECT 
            ciudad,
            fecha_pron,
            modelo_id,
            unidades,
            completo,
            dia,
            valor,
            fuente
        FROM predicciones_ia 
        WHERE ciudad = $1 
        AND DATE(fecha_pron) = $2
        ORDER BY dia ASC
        """
        
        # Ejecutar consulta
        async with db_pool.acquire() as conn:
            rows = await conn.fetch(query, ciudad, fecha_pron)
        
        if not rows:
            return JSONResponse(
                status_code=404,
                content={"message": "no data found"}
            )
        
        # Procesar resultados
        first_row = rows[0]
        pronosticos = []
        
        for row in rows:
            pronosticos.append(PronosticoItem(
                dia=row['dia'].strftime('%Y-%m-%d') if isinstance(row['dia'], datetime) else str(row['dia']),
                valor=float(row['valor']),
                fuente=row['fuente'] or 'observado'
            ))
        
        # Formatear fecha de pron√≥stico
        fecha_pron_iso = first_row['fecha_pron']
        if isinstance(fecha_pron_iso, datetime):
            fecha_pron_iso = fecha_pron_iso.isoformat()
        else:
            fecha_pron_iso = str(fecha_pron_iso)
        
        # Construir respuesta
        response = PronosticoResponse(
            ciudad=first_row['ciudad'],
            fecha_pron=fecha_pron_iso,
            modelo=first_row['modelo_id'] or 'IA_Model',
            unidades=first_row['unidades'] or 'ppb',
            pronos=pronosticos
        )
        
        logger.info(f"‚úÖ Consulta IA exitosa: {ciudad}, {fecha_pron}, {len(pronosticos)} registros")
        return response
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"‚ùå Error en consulta IA: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"Error interno del servidor: {str(e)}"
        )

@app.get(
    "/get_wrf_resume/{contaminante}/{ciudad}/{fecha_pron}",
    response_model=PronosticoResponse,
    responses={
        404: {"model": ErrorResponse, "description": "No se encontraron datos"},
        500: {"model": ErrorResponse, "description": "Error interno del servidor"}
    }
)
async def get_wrf_resume_legacy(
    contaminante: str = Path(..., description="Contaminante (ej: ozono, pm10, co, etc.)"),
    ciudad: str = Path(..., description="Ciudad de la predicci√≥n"),
    fecha_pron: str = Path(..., description="Fecha de pron√≥stico en formato YYYY-MM-DD")
):
    """
    Endpoint legacy para compatibilidad. Redirige al endpoint principal.
    """
    # Redirigir al endpoint principal
    return await get_ai_vi_transformer01(contaminante, ciudad, fecha_pron)

if __name__ == "__main__":
    # Configuraci√≥n para desarrollo usando la misma configuraci√≥n que la app Dash
    uvicorn.run(
        "api_service:app",
        host=API_CONFIG['host'],
        port=API_CONFIG['port'],
        reload=API_CONFIG['debug'],
        log_level="info"
    )
